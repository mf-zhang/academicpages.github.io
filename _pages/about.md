---
permalink: /
title: "üëãüèª Hi there"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm Mingfang Zhang (Âº†Èì≠Êñπ), a PhD student at the University of Tokyo, supervised by Prof. [Yoichi Sato](https://sites.google.com/ut-vision.org/ysato/).

My research interests lie in computer vision and first-person perspective multimodal human activity understanding.

### üéì Education
* Ph.D. in Information Science @ The University of Tokyo (2026.3 expected)
* M.Sc. in Information Science @ The University of Tokyo (2023.3)
* B.Sc. in Computer Science @ Nanjing University (2020.7)

### üíº Research Intern Experience
* Activity Understanding Team at CyberAgent AI Lab, mentored by [Ryo Yonetani](https://yonetaniryo.github.io) (2024)
* OpenGVLab at Shanghai AI Laboratory, mentored by [Yifei Huang](https://hyf015.github.io), [Yu Qiao](https://mmlab.siat.ac.cn/yuqiao) (2023)
* Media Computing Group at Microsoft Research Asia, mentored by [Jinglu Wang](https://www.microsoft.com/en-us/research/people/jinglwa/), [Yan Lu](https://www.microsoft.com/en-us/research/people/yanlu/) (2022)
* PCL, mentored by [Yinqiang Zheng](https://scholar.google.com/citations?user=JD-5DKcAAAAJ&hl=en), [Feng Lu](https://scholar.google.com/citations?user=9ggbm0QAAAAJ&hl=en) (2021)

### üìù Publications

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/eccv24_mae.jpeg" alt="ECCV 2024" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>Masked Video and Body-worn IMU Autoencoder for Egocentric Action Recognition</h3>
        <p>Mingfang Zhang, Yifei Huang, Ruicong Liu, Yoichi Sato</p>
        <p>European Conference on Computer Vision (ECCV), 2024</p>
        <p><a href="http://www.arxiv.org/pdf/2407.06628">Paper</a></p>
    </div>
</div>

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/cvpr24_egoexo.jpeg" alt="CVPR 2024" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World</h3>
        <p>Yifei Huang* , Guo Chen*, Jilan Xu*, Mingfang Zhang*, Lijin Yang, Baoqi Pei Hongjie Zhang, Lu Dong, Yali Wang, Limin Wang, Yu Qiao (* co-first author)</p>
        <p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>
        <p><a href="https://arxiv.org/pdf/2403.16182.pdf">Paper</a></p>
    </div>
</div>